{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c1a21a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (4.22.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (from transformers) (4.56.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (from transformers) (0.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.0)\n",
      "Requirement already satisfied: requests in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: openpyxl in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /mnt/storage-brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1457ccafdfd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install torch --user\n",
    "import json\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "%pip install transformers --user\n",
    "%pip install openpyxl --user\n",
    "\n",
    "from transformers import BertTokenizerFast,  BatchEncoding, BertModel, \\\n",
    "                            BertForTokenClassification\n",
    "from tokenizers import Encoding\n",
    "\n",
    "# %pip install ipywidgets --upgrade\n",
    "# %pip install jupyter --upgrade\n",
    "# %pip install seaborn --user\n",
    "# %pip install sentencepiece\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "077aa242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import preproc\n",
    "df = pd.read_excel(\"data/appliedAI_Use Case Library - Risk Class_TUM.ai.xlsx\", index_col=0, header=2)\n",
    "\n",
    "df = preproc(df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3882086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['risk'],\n",
    "                                                    stratify=df['risk'], \n",
    "                                                    test_size=0.25,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29fbaad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Use Case ID\n",
       "86      low-risk\n",
       "57      low-risk\n",
       "8       low-risk\n",
       "30      low-risk\n",
       "114     low-risk\n",
       "36     high-risk\n",
       "56     high-risk\n",
       "87      low-risk\n",
       "62      low-risk\n",
       "92      low-risk\n",
       "91      low-risk\n",
       "80      low-risk\n",
       "108     low-risk\n",
       "89      low-risk\n",
       "7       low-risk\n",
       "5      high-risk\n",
       "68      low-risk\n",
       "85      low-risk\n",
       "32      low-risk\n",
       "42     high-risk\n",
       "21      low-risk\n",
       "76      low-risk\n",
       "49      low-risk\n",
       "34      low-risk\n",
       "117     low-risk\n",
       "Name: risk, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "475f449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# create a dataset - currently all files loaded beforehand (woeks for smaller datasets)\n",
    "class RDataset(Dataset):\n",
    "    # A pytorch dataset class for holding data for a text labeling task.\n",
    "    # gets a parent directory of several datasets' directories\n",
    "    def __init__(self, model_name, X, y):\n",
    "        '''\n",
    "        Takes as input the name of a file containing sentences with a classification label (comma separated) in each line.\n",
    "        Stores the text data in a member variable X and labels in y\n",
    "        '''\n",
    "        \n",
    "        # Load a pre-trained tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "\n",
    "        self.encodings = self.tokenizer(X[\"desc\"].to_list(), return_tensors=\"pt\", padding=True)\n",
    "        self.y = y.replace({\"low-risk\": 0.0, \"high-risk\": 1.0}).to_list()\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.y[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86a4d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 384]) in the checkpoint and torch.Size([1, 384]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary\"\n",
    "dataset_train = RDataset(model_name,  X_train, y_train)\n",
    "dataset_test = RDataset(model_name, X_test, y_test)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1, ignore_mismatched_sizes=True)\n",
    "# model.config.num_labels = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ffb477eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f7562c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch:\n",
      "1 GPU(s) available.\n",
      "GPU-Name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch GPU capabilities:\n",
    "\n",
    "print(\"\\nPyTorch:\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('%d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('GPU-Name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6f66869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## other training parameters\n",
    "clip = 0.25            #gradient clipping\n",
    "lr = 0.00001#0.00003           #initial learning rate\n",
    "wdecay=1.2e-6          #weight decay applied to all weights\n",
    "epochs = 2             #maximum number of epochs\n",
    "#save = 'models/model.pt'      #path to save the final model\n",
    "\n",
    "train_max_number_batches = -1 # only for the sake of debugging. Set to -1 to be ignored\n",
    "inference_max_number_batches = -1 # only for the sake of debugging. Set to -1 to be ignored\n",
    "\n",
    "## log parameters\n",
    "log_interval = 100     #log interval during training\n",
    "log_interval_val = 100 #log interval during validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61c5d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Learner():\n",
    "    def __init__(self,train_loader, val_loader, model, optimizer, device, loss_fn=None):\n",
    "        self.train_loader= train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.model = model \n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = device\n",
    "        \n",
    "    def evaluate(self, loader):\n",
    "        eval_loss = 0\n",
    "        self.model.eval()\n",
    "        for b, inp in tqdm.tqdm(enumerate(loader), total=len(loader), position=0, leave=True):\n",
    "            with torch.no_grad():\n",
    "                inp = {k:v.clone().detach().to(device) for (k,v) in inp.items()}\n",
    "                \n",
    "                output = self.model(**inp)\n",
    "                #loss = self.loss_fn(log_pred, y)\n",
    "                logits = output.logits\n",
    "                \n",
    "                loss = self.loss_fn(logits, inp[\"labels\"], pos_weight=torch.tensor(9))\n",
    "                \n",
    "                eval_loss += loss.item()\n",
    "            \n",
    "        eval_loss /= len(loader)\n",
    "        \n",
    "        return eval_loss\n",
    "    \n",
    "    def train(self,n_epochs, train_losses, val_losses, early_stopping=True, es_limit=3):\n",
    "\n",
    "        if early_stopping:\n",
    "            min_val_loss = np.inf\n",
    "            no_improve = 0\n",
    "        \n",
    "        \n",
    "        for e in range(n_epochs):\n",
    "            # train\n",
    "            train_loss = 0\n",
    "            self.model.train()\n",
    "            for b, inp in tqdm.tqdm(enumerate(self.train_loader), total=len(self.train_loader), position=0, leave=True):\n",
    "                inp = {k:v.clone().detach().to(device) for (k,v) in inp.items()}\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(**inp)\n",
    "\n",
    "                logits = output.logits\n",
    "\n",
    "                print(inp[\"labels\"])\n",
    "                loss = self.loss_fn(logits, inp[\"labels\"], pos_weight=torch.tensor(10))\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # evaluate (train, validation)\n",
    "            train_loss = self.evaluate(self.train_loader)\n",
    "            val_loss = self.evaluate(self.val_loader)\n",
    "\n",
    "            # early stopping\n",
    "            if early_stopping:\n",
    "                if val_loss < min_val_loss:\n",
    "                    min_val_loss = val_loss\n",
    "                    torch.save(self.model, \"models/deberta\")\n",
    "                    no_improve = 0\n",
    "                else:\n",
    "                    no_improve += 1\n",
    "            if no_improve > es_limit:\n",
    "                print(\"Early stopped\")\n",
    "                self.model = torch.load(\"models/deberta\")\n",
    "                break\n",
    "            \n",
    "            print(f\"After {e+1} epochs: \")\n",
    "            print(f\"Train loss: {train_loss:.3}\")\n",
    "            print(f\"Val loss: {val_loss:.3}\\n\")\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    \n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(dataset_test, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wdecay)\n",
    "loss_fn = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "train_losses, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91189454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/var/tmp/pbs.12802678.meta-pbs.metacentrum.cz/ipykernel_894246/1032613092.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/storage/brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n",
      "/storage/brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
      "/storage/brno2/home/xstary1/brno6/.local-adv.SIF/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
      " 20%|██        | 2/10 [00:00<00:00,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([1., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:00<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.37it/s]\n",
      " 50%|█████     | 5/10 [00:00<00:00, 47.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 54.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 52.40it/s]\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 epochs: \n",
      "Train loss: 0.42\n",
      "Val loss: 1.81\n",
      "\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.67it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 0., 1., 0., 1., 0., 0.], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 53.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 51.72it/s]\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 2 epochs: \n",
      "Train loss: 0.39\n",
      "Val loss: 1.46\n",
      "\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.33it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 53.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 51.94it/s]\n",
      " 20%|██        | 2/10 [00:00<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 3 epochs: \n",
      "Train loss: 0.328\n",
      "Val loss: 2.64\n",
      "\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0., 1., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.10it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 1., 0.], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 60.76it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 53.17it/s]\n",
      " 20%|██        | 2/10 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 4 epochs: \n",
      "Train loss: 0.388\n",
      "Val loss: 2.49\n",
      "\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.14it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0')\n",
      "tensor([1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 53.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 53.20it/s]\n",
      " 20%|██        | 2/10 [00:00<00:00, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 epochs: \n",
      "Train loss: 0.257\n",
      "Val loss: 3.17\n",
      "\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.56it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 54.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 53.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(train_loader, val_loader, model, optim, device, loss_fn=loss_fn)\n",
    "train_losses, val_losses = learner.train(50, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "582593a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/var/tmp/pbs.12802678.meta-pbs.metacentrum.cz/ipykernel_894246/1032613092.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 10/10 [00:00<00:00, 50.32it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0')\n",
      "tensor([-2.5821, -2.6358, -2.6894,  2.2186,  2.1958, -2.6956, -2.7522,  2.2867],\n",
      "       device='cuda:0')\n",
      "tensor([1., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "tensor([ 2.1468, -2.6989, -2.6235, -2.6923, -2.6467,  2.2090, -2.6235, -2.6923],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([-2.7415, -2.4818, -2.6506, -2.6419, -2.7578, -2.6593, -2.5627, -2.7123],\n",
      "       device='cuda:0')\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "tensor([ 2.2090,  2.1793, -2.5806, -2.4287, -2.5437,  2.2670, -2.7243, -2.7422],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')\n",
      "tensor([-2.4709, -2.6875, -2.6983, -2.7205,  2.2444, -2.7782, -2.6785, -2.5667],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([-2.5133, -2.6366, -2.5085, -2.5839, -2.7569, -2.4353, -2.7698, -2.6358],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([-2.5904, -2.6831, -2.7259, -2.5794, -2.7522, -2.5540, -2.5821, -2.5953],\n",
      "       device='cuda:0')\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 2.2638, -2.5425, -2.7682, -2.6627, -2.5821, -2.5075, -2.6071,  2.1793],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')\n",
      "tensor([-2.6289, -2.7193, -2.6770, -2.5177, -2.6939, -2.7039,  2.3061, -2.7032],\n",
      "       device='cuda:0')\n",
      "tensor([0.], device='cuda:0')\n",
      "tensor([-2.7145], device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([-2.7577, -2.3126, -0.8082, -2.4205, -2.6596, -2.3934, -2.2007, -2.6076,\n",
      "         2.2637, -1.0296, -2.4633, -2.0144, -2.5560, -2.5063, -1.5995, -2.7587],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 45.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "tensor([-2.6222, -2.7232, -2.7422, -2.5621, -2.5753, -0.9221, -1.6190,  2.2090,\n",
      "        -2.6923], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, loader, device=\"cpu\", verbose=False):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    for b, inp in tqdm.tqdm(enumerate(loader), total=len(loader), position=0, leave=True):\n",
    "        with torch.no_grad():\n",
    "            inp = {k:v.to(device) for (k,v) in inp.items()}    \n",
    "            output = model(**inp)\n",
    "            \n",
    "        y_true.append(inp[\"labels\"])\n",
    "        print(inp[\"labels\"])\n",
    "        #print(amask)\n",
    "        print(output.logits)\n",
    "        y_pred.append((output.logits > 0).float())\n",
    "    #print(len(y_pred))\n",
    "    #print(y_pred[0].shape)\n",
    "    return torch.cat(y_pred, dim=0).to(\"cpu\"), torch.cat(y_true, dim=0).to(\"cpu\") \n",
    "\n",
    "pred_train, y_train = predict(model, train_loader, device=device, verbose=False)\n",
    "pred_val, y_val = predict(model, val_loader, device=device, verbose=False)\n",
    "# pred_test, y_test = predict(model, test_loader, device=device, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ada0f000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0.]),\n",
       " Use Case ID\n",
       " 86      low-risk\n",
       " 57      low-risk\n",
       " 8       low-risk\n",
       " 30      low-risk\n",
       " 114     low-risk\n",
       " 36     high-risk\n",
       " 56     high-risk\n",
       " 87      low-risk\n",
       " 62      low-risk\n",
       " 92      low-risk\n",
       " 91      low-risk\n",
       " 80      low-risk\n",
       " 108     low-risk\n",
       " 89      low-risk\n",
       " 7       low-risk\n",
       " 5      high-risk\n",
       " 68      low-risk\n",
       " 85      low-risk\n",
       " 32      low-risk\n",
       " 42     high-risk\n",
       " 21      low-risk\n",
       " 76      low-risk\n",
       " 49      low-risk\n",
       " 34      low-risk\n",
       " 117     low-risk\n",
       " Name: risk, dtype: object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "65d3f2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa980c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc9caf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary on TRAIN set:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    high-res       1.00      0.97      0.98        63\n",
      "     low-res       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.97        73\n",
      "   macro avg       0.92      0.98      0.95        73\n",
      "weighted avg       0.98      0.97      0.97        73\n",
      "\n",
      "[[61  2]\n",
      " [ 0 10]]\n",
      "*****************************************************\n",
      "\n",
      "Summary on VAL set:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    high-res       0.87      0.95      0.91        21\n",
      "     low-res       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.68      0.60      0.62        25\n",
      "weighted avg       0.81      0.84      0.82        25\n",
      "\n",
      "[[20  1]\n",
      " [ 3  1]]\n",
      "*****************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, pred, y in zip([\"TRAIN\", \"VAL\"], [pred_train, pred_val], [y_train, y_val]):\n",
    "    print(f\"Summary on {name} set:\")\n",
    "    print()\n",
    "    print(classification_report(y.ravel(), pred.ravel(), target_names=[\"high-res\", \"low-res\"]))\n",
    "    print(confusion_matrix(y.ravel(), pred.ravel()))\n",
    "    print(\"*\"*53)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1c2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc46cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e8661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413464a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2f951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316383d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5f368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5ed94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
