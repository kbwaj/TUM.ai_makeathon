Note: This document is a merger of Annex III in (a) the proposed AI Act as of April 20, 2021 and (b) the consolidated amendments by IMCO and LIBE as tabled on 20.04.2022. 


Additions to the proposal from 2021 are marked as bold and deletions as strikethrough.  


Disclaimer: This is a working document and not official. It is intended as an aid for understanding the AI Act and the impact of changes. It is not to be used as the basis for legal advise.
	

ANNEX III
HIGH-RISK AI SYSTEMS REFERRED TO IN ARTICLE 6 (2)
High-risk AI systems pursuant to Article 6(2) are the AI systems listed in any of the following areas:
1.Biometric identification and categorisation of natural persons:
(a)        AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons;


2.Management and operation of critical infrastructure:
(a)        AI systems intended to be used as safety or security components in the management and operation of road traffic and the supply of water, gas, heating, electricity and internet.


3.Education and vocational training:
(a)        AI systems intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;
(b)        AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to educational institutions, for determining learning objectives, and for allocating personalised learning tasks to students.
(c)        AI systems intended to be used by children in ways that have a significant impact on their personal development, including through personalised education or their cognitive or emotional development


4.Employment, workers management and access to self-employment:
(a)        AI systems intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;
(b)        AI intended to be used for making decisions on promotion and termination of work-related contractual relationships, for task allocation and for monitoring and evaluating performance and behavior of persons in such relationships.
5.Access to and enjoyment of essential private services and public services and benefits:
(a)        AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;
(b)        AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;
(c)        AI systems intended to be used for making decisions or assisting in making decisions on the eligibility of natural persons for health and life insurance;
(d)        AI systems intended to be used to evaluate and classify emergency calls by natural persons or dispatch, or to establish priority in the dispatching of emergency first response services, including by police and law enforcement, firefighters and medical aid, as well as of emergency healthcare patient triage systems;


6.Law enforcement:
(a)        AI systems intended to be used by law enforcement authorities for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or the risk for potential victims of criminal offences;
Justification: predictive policing was inserted in article 5.
(b)        AI systems intended to be used by law enforcement authorities as polygraphs and similar tools or to detect the emotional state of a natural person;
(c)        AI systems intended to be used by law enforcement authorities to detect deep fakes as referred to in article 52(3);
(d)        AI systems intended to be used by law enforcement authorities for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;
(e)        AI systems intended to be used by law enforcement authorities for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups;
Justification: predictive policing was inserted in article 5.
(f)        AI systems intended to be used by law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of detection, investigation or prosecution of criminal offences;
(g)        AI systems intended to be used for crime analytics regarding natural persons, allowing law enforcement authorities to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.


7.Migration, asylum and border control management:
(a)        AI systems intended to be used by competent public authorities as polygraphs and similar tools or to detect the emotional state of a natural person;
(b)        AI systems intended to be used by competent public authorities to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;
(c)        AI systems intended to be used by competent public authorities for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;
(d)        AI systems intended to assist competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.


8.Administration of justice and democratic processes:
(a)        AI systems intended to assist a judicial authority in researching and interpreting facts and the law and in applying the law to a concrete set of facts.
(b)        AI systems intended to be used by political parties, political candidates, public authorities, or on their behalf for influencing natural persons in the exercise of their vote in local, national, or European Parliament elections;
(c)        AI systems intended to process or count voting ballots for local, national or European Parliament elections;


8a. Other applications:
(a)         AI systems intended to be used to generate, on the basis of limited human input, complex text content that would falsely appear to a person to be human generated and authentic, such as news articles, opinion articles, novels, scripts, and scientific articles;
(b)         AI systems intended to be used to generate or manipulate audio or video content that appreciably resembles existing natural persons, in a manner that significantly distorts or fabricates the original situation, meaning, content, or context and would falsely appear to a person to be authentic.


Version: Juli 2022                                                                              Page