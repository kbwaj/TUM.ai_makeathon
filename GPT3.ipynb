{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ac474b-884b-46f4-9e05-919702e132a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.23.1.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.60.0)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.10.0.2)\n",
      "Collecting pandas-stubs>=1.1.0.11\n",
      "  Using cached pandas_stubs-1.5.0.220926-py3-none-any.whl (136 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.23.2)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.4.3)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.2.3->openai) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Collecting types-pytz>=2022.1.1\n",
      "  Using cached types_pytz-2022.2.1.0-py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai) (1.16.0)\n",
      "Building wheels for collected packages: openai\n",
      "  Building wheel for openai (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai: filename=openai-0.23.1-py3-none-any.whl size=54505 sha256=aad5ff5ce690aabd369c9edee90e1c5b2eba22a98bc14f46ad923fcaac65192a\n",
      "  Stored in directory: /Users/robertlukoshko/Library/Caches/pip/wheels/0c/71/e7/f9793f0f9d25a15d3e4a63a21258f575fd3ad662c3e26be72d\n",
      "Successfully built openai\n",
      "Installing collected packages: types-pytz, pandas-stubs, openai\n",
      "Successfully installed openai-0.23.1 pandas-stubs-1.5.0.220926 types-pytz-2022.2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a1fd9b9-5ae2-42f2-ba28-02d9a62b4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = "
   ]
  },
  {
   "cell_type": "raw",
   "id": "34359102-7234-4dbc-a477-ee17d67fa490",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. check:\n",
    "openai tools fine_tunes.prepare_data -f <LOCAL_FILE>\n",
    "This tool accepts different formats, with the only requirement that they contain a prompt and a completion column/key. You can pass a CSV, TSV, XLSX, JSON or JSONL file, and it will save the output into a JSONL file ready for fine-tuning, after guiding you through the process of suggested changes.\n",
    "\n",
    "2. train\n",
    "openai api fine_tunes.create -t <TRAIN_FILE_ID_OR_PATH> -m <BASE_MODEL>\n",
    "# openai api fine_tunes.create -t test.jsonl -m ada --suffix \"custom model name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f204238-deec-4a19-8d2c-f0e8c4894f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"laws.txt\", 'r') as f:\n",
    "    laws = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b2af606e-8d0b-4e88-b17e-30abaa4772b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "laws = laws.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2b166ae-ac49-439b-bc55-aca055506ce5",
   "metadata": {},
   "source": [
    "description = \"\"\"\n",
    "During the recruitment process, not only the hard skills of candidate are rated: inside, but also whether the soft skills, personality and behavior fit the requirements of the position. Traditionally, this is done according to the impression of trained recruiters, but this procedure is susceptible to misjudgments due to the very limited time during the few rounds of discussion and possible unconscious bias. Computer-vision-based AI algorithms can support this part of the interview analysis by recognizing subtle differences in words, voice, body language, facial expressions and gestures and then predicting behavior patterns and different personality traits based on the information collected. As a result, you can supplement and expand the human analysis with data -based knowledge and thus increase the completeness and speed of the evaluation and reduce the risk of possible biasing decisions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "33dec04c-179e-432b-8be0-3e62a4dc673b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d249743-c3c0-4103-bcc8-d3f93e111f7a",
   "metadata": {},
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0dd648c-79e8-49f8-a476-47cafc48a5d5",
   "metadata": {},
   "source": [
    "description = \"\"\"In the case of dynamic pricing, also Surge Pricing, Demand Pricing, Real-Time Pricing or Algorithmic Pricing, the price is flexible and is based on request, supply, competition price and by-product prices. The price can even change from customer to customer depending on the purchase behavior. Dynamic pricing enables suppliers: inside, more flexible and more individually adjusting the prices. Traditionally, the pricing was determined on the basis of static price rules that used a limited amount of data input. The explosive growth of big data and the potential contained therein for the development of AI and machine learning approaches for price strategies have opened new opportunities for intelligent price solutions. The technology of mechanical learning lifts the dynamic pricing to the next stage, since it can process much larger data records and take into account various influencing factors in order to predict the effects of price changes.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9333091c-ea96-4fdd-bc09-44ac4ae1ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ca53a4c8-cb65-4f66-939d-8c07b5ef64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for law in laws:\n",
    "    output.append(json.dumps({\"text\": law, 'metadata': 'laws'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6897b7da-c770-4489-8f79-fe90355051ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ou.txt\", 'w') as f:\n",
    "    f.write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dc7b4c48-5dee-4ff4-bd84-9c2cddf861c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.File.create(\n",
    " file=open(\"ou.txt\" ,'r'),\n",
    " purpose='answers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7791ab01-9ae3-499b-91c1-980aa02ca9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-Bil7GJIkeNbj8rJurv0V210c at 0x1172f0bd0> JSON: {\n",
       "  \"bytes\": 5980,\n",
       "  \"created_at\": 1664697333,\n",
       "  \"filename\": \"file\",\n",
       "  \"id\": \"file-Bil7GJIkeNbj8rJurv0V210c\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"answers\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f67f1081-6b34-4bfe-a53f-a51b7ae61aa4",
   "metadata": {},
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bf4271c-dbe0-4aa4-8ac5-15eae66a449e",
   "metadata": {},
   "source": [
    "openai.Answer.create(\n",
    "    search_model=\"ada\", \n",
    "    model=\"curie\", \n",
    "    question=\"which puppy is happy?\", \n",
    "    file=\"file-uL7LJRvYClkzPPOZN0zYsQkO\", \n",
    "    examples_context=\"In 2017, U.S. life expectancy was 78.6 years.\", \n",
    "    examples=[[\"What is human life expectancy in the United States?\", \"78 years.\"]], \n",
    "    max_rerank=10,\n",
    "    max_tokens=5,\n",
    "    stop=[\"\\n\", \"<|endoftext|>\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8205d6b-ab65-4df7-a03e-acfc6b6101c8",
   "metadata": {},
   "source": [
    "response[\"selected_documents\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da96b8f5-404f-46fe-9d9a-716ac6c63628",
   "metadata": {},
   "outputs": [],
   "source": [
    "description=\"\"\"Knowledge -based authentication can be frustrating and easy to abuse. The device -based verification and one -off pass codes are also inflexible and insecure. Voice biometry offers the opportunity to use a person's voice as a clearly identifying biological characteristic to authenticate it. Also referred to as language verification or speaker recognition, language biometry enables quick, smooth and highly safe access for a number of applications, call centers, mobile and online applications to chatbots, IoT devices and physical access. Progress in the language biometry technology based on artificial intelligence (AI) means that it is now able to replace conventional password authentication systems and bring many significant advantages that are not only limited to digital registrations.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dbe07317-3110-4645-baf3-87da6aa17d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(text):\n",
    "    response = openai.Answer.create(\n",
    "\n",
    "    model=\"text-davinci-002\",\n",
    "    file=\"file-Bil7GJIkeNbj8rJurv0V210c\",\n",
    "    question=f\"The startup which is {description}. Concerns the laws above?\",\n",
    "    examples_context=\"In 2017, U.S. life expectancy was 78.6 years.\",\n",
    "    examples=[[\"What is human life expectancy in the United States?\", \"78 years.\"]],\n",
    "    max_tokens=256,\n",
    "    )\n",
    "    return response['answers'], response[\"selected_documents\"][-1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2428d3e5-01d1-478a-97ff-ff776a6293b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['No'],\n",
       " 'AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons.')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e190e0d-cb43-410f-8f73-f0d5ec9926a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
