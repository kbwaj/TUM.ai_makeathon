{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19404d5-6ba9-49c4-8879-36ddb717a8fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ea6abc-1fbd-458c-8b6a-b89ac28664ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.97)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304988e-2856-47eb-9a41-a037064f1352",
   "metadata": {
    "tags": []
   },
   "source": [
    "## installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d965561e-ff5a-4cd3-b706-74d3f808660f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-profiling[notebook] in /opt/conda/lib/python3.7/site-packages (3.3.0)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.1.12)\n",
      "Requirement already satisfied: joblib~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (1.1.0)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.13.2)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.2.0)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (4.64.1)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.12.2)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (2.11.3)\n",
      "Requirement already satisfied: matplotlib<3.6,>=3.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (3.5.3)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.5,>1.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (1.3.5)\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (1.7.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (6.0)\n",
      "Requirement already satisfied: missingno<0.6,>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.4.2)\n",
      "Requirement already satisfied: seaborn<0.12,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.11.2)\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (2.28.1)\n",
      "Requirement already satisfied: pydantic<1.10,>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (1.9.2)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (0.7.5)\n",
      "Requirement already satisfied: multimethod<1.9,>=1.4 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (1.4)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (1.21.6)\n",
      "Requirement already satisfied: jupyter-core>=4.6.3 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (4.11.1)\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (8.0.2)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling[notebook]) (7.3.5)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (2.7.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (9.2.0)\n",
      "Requirement already satisfied: imagehash in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (4.3.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling[notebook]) (5.4.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling[notebook]) (3.0.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling[notebook]) (7.33.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling[notebook]) (6.16.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling[notebook]) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling[notebook]) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.3.4->pandas-profiling[notebook]) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.3.4->pandas-profiling[notebook]) (1.5.5)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.3.4->pandas-profiling[notebook]) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.3.4->pandas-profiling[notebook]) (6.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.3.4->pandas-profiling[notebook]) (0.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (4.37.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.4.0,<1.5,>1.1->pandas-profiling[notebook]) (2022.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pydantic<1.10,>=1.8.1->pandas-profiling[notebook]) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (2022.9.24)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling[notebook]) (0.5.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling[notebook]) (1.6.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling[notebook]) (5.9.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (2.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (59.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (3.0.31)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.18.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (5.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->pandas-profiling[notebook]) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.7/site-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling[notebook]) (0.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pandas-profiling[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6360d41-2c19-44d2-9289-278ed123ed19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.7/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ef27ac-5ec5-49e5-af32-39549f779281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87311a8-1129-4d4c-bc47-a3f32e4620bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (8.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.0.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.33.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (6.16.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.13.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (59.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.31)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf60295-68c2-431a-b4fb-22ff368697dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.13.3)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.9.9)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.19.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a34c77ee-3c1c-47ac-b9db-fa1be424dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.7/site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8a194a-3843-4ac1-a4d9-ee00b5f873e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/jupyter/makethon/TUM-Makeathon-22\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "444c80d7-a605-4fd7-8de2-8df366c9ae02",
   "metadata": {},
   "source": [
    "os.system('pip install -q transformers')  # was uninstall\n",
    "os.system('pip install -q tokenizers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0bff52-e9dc-46da-958c-3138f5657de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch==1.12.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f92b4-ada8-4819-a464-ecaa1a8aafff",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d007b5-7733-4e8f-ac1f-91ef859980c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification==0.1.7 in /opt/conda/lib/python3.7/site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.21.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from research import tools\n",
    "from importlib import reload\n",
    "\n",
    "# visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Basic\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV,\n",
    "    cross_val_score, KFold\n",
    ")\n",
    "os.system('pip install iterative-stratification==0.1.7')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils import checkpoint\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Hugging face\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "\n",
    "# XGB\n",
    "import xgboost as xgb\n",
    "os.environ['WANDB_SILENT']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6aa8ff5-33b1-4d38-bd47-1cc2099c5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "font = {'family':'Helvetica, Ariel',\n",
    "        'weight':'normal',\n",
    "        'size':12}\n",
    "plt.rc('font', **font)\n",
    "sns.set(rc={\"figure.dpi\": 300, 'savefig.dpi': 300})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "FIG_FONT = dict(family=\"Helvetica, Ariel\", weight=\"bold\", color=\"#7f7f7f\")\n",
    "sns.set_palette('Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775d64ae-2ba7-44cd-a4de-f4a5ad224c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3775ba09-4161-4321-a172-6b6f166a9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=False\n",
    "    competition='makethon'\n",
    "    debug=False\n",
    "    apex=False # automatic mixed precision\n",
    "    print_freq=10\n",
    "    num_workers=4\n",
    "    gradient_checkpointing=True\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5 # The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0 following a half-cosine).\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr=2e-3\n",
    "    decoder_lr=2e-3\n",
    "    min_lr=1e-3\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    target_cols=['risk']  # TODO\n",
    "    seed=42\n",
    "    train=True\n",
    "\n",
    "if CFG.wandb:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv('research/settings.env')\n",
    "    wandb_api = os.environ['WANDB']\n",
    "    run = wandb.init(\n",
    "        project='AI4CODE', \n",
    "        name=CFG.model_name,\n",
    "        config=class2dict(CFG),\n",
    "        # group=CFG.model_name,\n",
    "        job_type=\"train\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c282da6-5d15-4087-9041-26115a355e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=42)\n",
    "LOGGER = tools.get_logger(filename='logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8f589-9c44-4211-a177-f2a63943f47b",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4a7ae0c-4f18-4917-855e-1b492f89af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94913cf1-a7dc-47f0-b775-6ec9520855c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "775e9584-a55c-4fe5-8ff3-b9f62d5f4fb5",
   "metadata": {},
   "source": [
    "ideas_from_law_df = pd.read_csv(\"research/data/generated_ideas.csv\")\n",
    "ideas_from_law_df = pd.concat([ideas_from_law_df, pd.DataFrame([[None, None, 'nothing']], columns=ideas_from_law_df.columns)], axis=0)\n",
    "labelencoder = LabelEncoder()\n",
    "CATEGORIES = ideas_from_law_df['tags'].unique()  # law\n",
    "ideas_from_law_df['label'] = labelencoder.fit_transform(ideas_from_law_df['tags'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fe6e4ca-f702-4357-ba9b-84b9a1537d93",
   "metadata": {},
   "source": [
    "ideas_from_law_df = ideas_from_law_df.dropna(subset=['idea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324cd4bb-e6b5-42ba-b4a3-4618b1043987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"research/data/appliedAI_Use Case Library - Risk Class_TUM.ai.xlsx\"\n",
    ")\n",
    "df['risk'] = (\n",
    "    df['Is the AI System high-risk or low risk?'].replace(\n",
    "        {\n",
    "            'low-risk' : 0,\n",
    "            'high-risk': 1,\n",
    "            'It is unclear': None\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df = df.dropna(subset=['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a4c7682-5f06-4746-abfa-dfa835d60ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['human']=(\n",
    "    df['Does the AI System interact with humans?'].replace(\n",
    "        {\n",
    "            'no' : 0,\n",
    "            \n",
    "            'yes': 1,\n",
    "            'yes - real time?': 1,\n",
    "            'real time?': 1,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df = df.dropna(subset=['human'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd4c7d19-3542-41d1-b77e-0e2e176d8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[['Description', 'Business Challenge', 'AI System', 'human']]\n",
    "train_df = train_df.reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70fbf3df-22c9-4494-b50c-295f6b5179b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "train_dublicate_indexes = train_df.loc[train_df['risk']==1].drop_duplicates(subset=['Description'])['index'].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4e96bcb-a3ed-4d0b-b41d-f1963730bf43",
   "metadata": {},
   "source": [
    "marking_classified_data = [\"human resources services\",\n",
    "\"worker evaluation\",\n",
    "\"worker evaluation\",\n",
    "\"human resources services\",\n",
    "\"human resources services\",\n",
    "\"biometric identification\",\n",
    "\"biometric identification\",\n",
    "\"biometric identification\",\n",
    "\"biometric identification\",\n",
    "\"legal documents generation\",\n",
    "\"legal documents generation\",\n",
    "\"biometric identification\",\n",
    "\"manage access to public goods\",\n",
    "\"credit scoring\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6fc658c-c796-4468-b0fc-f6cd40e86585",
   "metadata": {},
   "source": [
    "train_df.loc[train_df['risk']==1, 'label'] = labelencoder.transform(marking_classified_data)\n",
    "train_df.loc[train_df['risk']==1, 'tags'] = marking_classified_data\n",
    "train_df.loc[train_df['risk']==0, 'tags'] = 'nothing'\n",
    "train_df.loc[train_df['risk']==0, 'label'] = labelencoder.transform(train_df.loc[train_df['risk']==0, 'tags'])\n",
    "train_df['description'] = train_df['Description']\n",
    "train_df = train_df[['description', 'label', 'risk', 'tags']]\n",
    "ideas_from_law_df['risk'] = 1\n",
    "test_filtered = train_df[train_df['risk']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753cc62-aeb2-441f-8ea8-295ec617fb4b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "ba90e994-25df-442e-a918-ee7cd2834bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.description = df['description'].values\n",
    "        # self.biz_challendge = df['Business Challenge'].values\n",
    "        # self.ai_system = df['AI System'].values\n",
    "        self.labels = nn.functional.one_hot(\n",
    "            torch.LongTensor(labelencoder.transform(df['tags'])),\n",
    "            num_classes=len(CATEGORIES)\n",
    "        )\n",
    "        # self.labels = df['label'].values\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\",\n",
    "            do_lower_case=True\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.description)\n",
    "    \n",
    "    def tokenize(self, data):\n",
    "        return self.tokenizer.encode_plus(\n",
    "            data,\n",
    "            None,\n",
    "            add_special_tokens=False,\n",
    "            max_length=CFG.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.tokenize(str(self.description[item]))\n",
    "        labels = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "        return ids, mask, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54956863-ab82-4146-8525-7f0f08e8e786",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "ff1a04b0-bb8d-495f-827a-41649a344745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.distill_bert = AutoModel.from_pretrained(\n",
    "            \"bert-base-uncased\"\n",
    "        )\n",
    "        \n",
    "        self.top1 = nn.Linear(768*1, 768)\n",
    "        self.top2 = nn.Linear(768, 768)\n",
    "        self.top3 = nn.Linear(768, len(CATEGORIES))  # classify the data into N laws described in the training dataset\n",
    "\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.3)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.3)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0][:, 0, :]\n",
    "        # select the first token only as it is trained for classifier\n",
    "        x = F.relu(self.top1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.top2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.top3(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "88830032-a247-4502-932a-b8df27ca9edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimizer(net):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n",
    "        eps=1e-08)\n",
    "    return optimizer\n",
    "\n",
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch < 1:\n",
    "        lr = 5e-5\n",
    "    elif epoch < 2:\n",
    "        lr = 4e-5\n",
    "    elif epoch < 5:\n",
    "        lr = 3e-5\n",
    "    else:\n",
    "        lr = 2e-5\n",
    "\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = lr\n",
    "    return lr\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "e54a4dfe-9f7e-45ed-804d-4646adfaa910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    tbar = tqdm(val_loader)\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            labels.append(target.detach().cpu().numpy())\n",
    "    return np.concatenate(labels), np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "6556bb10-6c8c-4d12-8b9e-42b85f90ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, val_loader, criterion, weight_,  epochs):\n",
    "    np.random.seed(CFG.seed)\n",
    "    optimizer = get_optimizer(model)\n",
    "    for e in range(epochs):   \n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader)\n",
    "        lr = adjust_lr(optimizer, e)\n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            loss = criterion(pred, target)\n",
    "            loss = loss.mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "            \n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
    "        print(f\"MEAN TRAIN LOSS: {np.mean(loss_list)}\")\n",
    "        # print(pred)\n",
    "        # print(target)\n",
    "    y_val, y_pred = validate(model, val_loader)\n",
    "    val_loss = mean_absolute_error(y_val, y_pred)\n",
    "    print(f\"VAL LOSS: {val_loss}\")\n",
    "    return model, y_pred, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "dd40a501-21f9-47de-9f90-288b01fc3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([ideas_from_law_df, train_df[train_df['risk']==0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "f9871337-6bc0-421f-8154-2a537b61d880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ec7970bc034ae7ad9b52c1ff5437ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7111934039327833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e328fe18e04d90abca03fceb0ae899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7085811654726665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19f415723c34bb596c4c75302c4a609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7083253555827671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1ea5f8e28444e3a8307c0a6988b0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082899663183424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9db3eb893a344179f2390f24e285db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06850302964448929\n",
      "TRAIN DATA VALIDATION F1:  0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ec02aa4c7f424ab4729ee9275666d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.07982730865478516\n",
      "ORIGINAL DATASET VALIDATION F1:  0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7599da9dab60418bb8070158d5fe4e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7114660090870327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165e71ce1ce340c79474dedebf17069b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7089045590824551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d65eaf0fd9a45999d7e27db4cccc921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7083597289191352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fc7b12a49c4403b4b4c8b444d87e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7083898239665561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdcb78508cd423c9139069758366df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06858950108289719\n",
      "TRAIN DATA VALIDATION F1:  0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8d31174ba4427d8695ddd6a8dd8cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.0799955204129219\n",
      "ORIGINAL DATASET VALIDATION F1:  0.04\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe92d47694b446099e17d011f4daffff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7114891979429457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf5058e65f44229b608fec6882b722c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.708760314517551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcfe687240e42ce92586db8ac3acb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082650634977553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22750a9a8b8247b286173b2856c667f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.708234617445204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a138afa1fb414e48a036c01a6dabbf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06873365491628647\n",
      "TRAIN DATA VALIDATION F1:  0.08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188106e0a4b94c11b7480c66f30c4eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.07999581098556519\n",
      "ORIGINAL DATASET VALIDATION F1:  0.04\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203189e9234d4909bfa534bd7da40c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.711322037378947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0075bf1e194dd497a29b64b048131e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7085839973555671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d4ee7c099c4013962216f734718ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082084019978842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5767309c31432891c64e794dedb0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7077548636330498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61f9376cd014da0bb484874380aba40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06668904423713684\n",
      "TRAIN DATA VALIDATION F1:  0.20000000000000004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b0b2b96c0241918aeed925f4e83f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.07999607920646667\n",
      "ORIGINAL DATASET VALIDATION F1:  0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83bce349b034240924d2cf786a6611d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.711506085925632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82568856e774e7dbf79a198b8d3c39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.70887717405955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c0cb12180a42c9951ee8fb830c8a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082790493965149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5c252546f24fc8a94d1e1f3f0889f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082939399613275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30a6c9ccc4a4a9a8aa4ecec5b6bd6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06921383738517761\n",
      "TRAIN DATA VALIDATION F1:  0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16634bd7bd8949629d834909f0b5c1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.07999591529369354\n",
      "ORIGINAL DATASET VALIDATION F1:  0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471d08b1ea2046fd8774db665ad9fb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7115816632906596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e65bd206b04900b5d13b1bddb55fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.70890687306722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efdd4dbbc2f4a4186c2959a08a1be61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082421872350905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bd1d490d684445821df138655ed958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.708094925350613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cc6e012028438ca88f7a42c3a559fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06868073344230652\n",
      "TRAIN DATA VALIDATION F1:  0.08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6808dd59d99f4d0b9a41ec39f8862f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.0799962505698204\n",
      "ORIGINAL DATASET VALIDATION F1:  0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0562548309124d2882ba248e49f573f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7115552624066671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8a4c35fe944761b724bda72565e93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7090792960590786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0016d1a8644d34be7e6296c1bca612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7083513114187453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e063ad27f34a44a1d5edac32d2c320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7082859251234267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2f0ea0eb864320b7f423659fb6987e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06842271983623505\n",
      "TRAIN DATA VALIDATION F1:  0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ef1ec444b9492ea691685890bf67f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.07999533414840698\n",
      "ORIGINAL DATASET VALIDATION F1:  0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e80d5734874478caab0deaa99381f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7114655401971605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69afdbb76cd48e8bc744be14f902e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7087358607186212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196516d9ff754f8e8148b44521a5dadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7084454629156325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f657080b55d4d67b7a2bbcdbc2c2807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN TRAIN LOSS: 0.7080967995855544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4175454418e42e8a8d96f48923a6464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 0.06702466309070587\n",
      "TRAIN DATA VALIDATION F1:  0.24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5b173b91854c48b1b0b88847664e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL VAL VALIDATION: 0.07999438792467117\n",
      "ORIGINAL DATASET VALIDATION F1:  0.04\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "skf = StratifiedKFold(n_splits=8, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skf.split(train.values, train['label']):\n",
    "    model = CustomModel()\n",
    "    model.to(device)\n",
    "    print(\"Build the model\")\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, X_train)\n",
    "    valid_dataset = TrainDataset(CFG, X_test)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        # num_workers=-1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=False,\n",
    "        # num_workers=-1,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    model, y_pred, y_val = train_fn(model, train_loader, valid_loader, criterion, None, epochs=4)\n",
    "    print(\"TRAIN DATA VALIDATION F1: \", f1_score(np.argmax(y_pred, axis=0),\n",
    "        np.argmax(y_val, axis=0), average='micro')\n",
    "         )\n",
    "    \n",
    "    valid_dataset = TrainDataset(CFG, test_filtered)\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=False,\n",
    "        # num_workers=-1,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    y_val, y_pred = validate(model, valid_loader)\n",
    "    val_loss = mean_absolute_error(y_val, y_pred)\n",
    "    print(f\"ORIGINAL VAL VALIDATION: {val_loss}\")\n",
    "    print(\"ORIGINAL DATASET VALIDATION F1: \", f1_score(np.argmax(y_pred, axis=0),\n",
    "        np.argmax(y_val, axis=0), average='micro')\n",
    "         )\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114061-63e2-4038-aeb3-0c1123453a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21760f9f-de57-4c6d-8800-41288a1f22c2",
   "metadata": {},
   "source": [
    "# y_val[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d324bf3-a790-44b5-9faf-a9f5118875f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598d4c7-3bd3-4166-a556-753aa148c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TrainDataset(CFG, X_test)\n",
    "valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=13,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12620787-41c1-4850-b37a-04ea03978157",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for idx, data in valid_loader:\n",
    "    inputs, target = read_data(data)\n",
    "    pred = model(*inputs)\n",
    "    preds.append(pred.detach().cpu().numpy())\n",
    "    labels.append(target.detach().cpu().numpy())\n",
    "np.concatenate(labels), np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "82595a4f-df50-4154-b666-5495f6764272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "winners = []\n",
    "for row in y_pred:\n",
    "    winners.extend(np.argsort(row)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "6c609161-4530-4280-bb3f-b109d2483241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "23e0aee0-a420-4447-96c8-876d75799e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({17: 34,\n",
       "         3: 37,\n",
       "         11: 37,\n",
       "         13: 55,\n",
       "         18: 9,\n",
       "         1: 19,\n",
       "         6: 13,\n",
       "         9: 1,\n",
       "         15: 1,\n",
       "         7: 1,\n",
       "         23: 1,\n",
       "         16: 3,\n",
       "         19: 1,\n",
       "         8: 1})"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6881087-bdc0-432f-a37a-1d0361433db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c580e2-7e91-4269-a668-61cd43b206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred)\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "cm = confusion_matrix(y_val, [1 if x>0.25 else 0 for x in y_pred])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m96"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
